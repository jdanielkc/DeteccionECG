{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import plotly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, regularizers, initializers, callbacks\n",
    "import random as python_random\n",
    "from numpy.random import seed\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(11)\n",
    "python_random.seed(123)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "from keras import backend as K\n",
    "from keras.backend import set_session\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "import tensorflow\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import json\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificacion(tamano,unico=True,numero=0):\n",
    "    #Vector de unos\n",
    "    if unico==True:\n",
    "        Y_train=np.ones(tamano)*numero\n",
    "    else:\n",
    "        for i in range(0,5):\n",
    "            if i==0:\n",
    "                Y_train=np.ones(tamano)*i\n",
    "            else:\n",
    "                vectorUnos=np.ones(tamano)\n",
    "                Y_train=np.insert(Y_train,len(Y_train),vectorUnos*i,axis=0)\n",
    "    return Y_train\n",
    "def load_data_test_gru():\n",
    "    # load your data using this function\n",
    "    path='C:\\\\Users\\jdani\\\\Documents\\\\TrabajoDeGrado\\\\BDConEspectrograma\\\\MatricesNumpyGuardadas_NA\\\\ECG_'\n",
    "    #importando patologias\n",
    "    ECG_Normal_Test=np.load(path+'Normal\\\\ECG_Normal_test.npy')\n",
    "    ECG_SBR_Test=np.load(path+'SBR\\\\ECG_SBR_Original.npy')\n",
    "    ECG_SBR_Test=ECG_SBR_Test[300:360,:,:]\n",
    "    ECG_AFIB_Test=np.load(path+'AFIB\\\\ECG_AFIB_test.npy')\n",
    "    ECG_STD_Test=np.load(path+'STD\\\\ECG_STD_test.npy')\n",
    "    ECG_STE_Test=np.load(path+'STE\\\\ECG_STE_test.npy')\n",
    "\n",
    "    y_Normal_Test=codificacion(len(ECG_Normal_Test),True,0)\n",
    "    y_SBR_Test=codificacion(len(ECG_SBR_Test),True,1)\n",
    "    y_AFIB_Test=codificacion(len(ECG_AFIB_Test),True,2)\n",
    "    y_STD_Test=codificacion(len(ECG_STD_Test),True,3)\n",
    "    y_STE_Test=codificacion(len(ECG_STE_Test),True,4)\n",
    "    \n",
    "    #Uniendo canales\n",
    "    ECG_Normal_Test=np.concatenate((ECG_Normal_Test[:,:,:,0],ECG_Normal_Test[:,:,:,1]),axis=1)\n",
    "    ECG_SBR_Test=np.concatenate((ECG_SBR_Test[:,:,:,0],ECG_SBR_Test[:,:,:,1]),axis=1)\n",
    "    ECG_AFIB_Test=np.concatenate((ECG_AFIB_Test[:,:,:,0],ECG_AFIB_Test[:,:,:,1]),axis=1)\n",
    "    ECG_STE_Test=np.concatenate((ECG_STE_Test[:,:,:,0],ECG_STE_Test[:,:,:,1]),axis=1)\n",
    "    ECG_STD_Test=np.concatenate((ECG_STD_Test[:,:,:,0],ECG_STD_Test[:,:,:,1]),axis=1)\n",
    "\n",
    "    #Generando X_train\n",
    "    X_test=np.concatenate((ECG_Normal_Test,\n",
    "                                ECG_SBR_Test,\n",
    "                                ECG_AFIB_Test,\n",
    "                                ECG_STE_Test,\n",
    "                                ECG_STD_Test))\n",
    "\n",
    "    Y_test=np.insert(y_Normal_Test,len(y_Normal_Test),y_SBR_Test,axis=0)\n",
    "    Y_test=np.insert(Y_test,len(Y_test),y_AFIB_Test,axis=0)\n",
    "    Y_test=np.insert(Y_test,len(Y_test),y_STD_Test,axis=0)\n",
    "    Y_test=np.insert(Y_test,len(Y_test),y_STE_Test,axis=0)    \n",
    "\n",
    "    print('Tamaño datos test: '+ str(X_test.shape))\n",
    "    print('Tamaño etiquetas de test: '+str(Y_test.shape))\n",
    "    \n",
    "    X_test=np.moveaxis(X_test,1,2)   \n",
    "    return X_test,Y_test\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño datos test: (6013, 102, 241)\n",
      "Tamaño etiquetas de test: (6013,)\n",
      "(6013, 241, 102)\n",
      "(6013, 5)\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = load_data_test_gru()\n",
    "y_val= keras.utils.to_categorical(y_val)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura convolucional sin normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño datos test: (6013, 102, 241)\n",
      "Tamaño etiquetas de test: (6013,)\n",
      "[0.28063511848449707, 0.9983375072479248, 0.9999468326568604, 0.9983552694320679]\n",
      "[0.654721200466156, 0.8877805471420288, 0.9718964695930481, 0.7989470362663269]\n",
      "[0.29116445779800415, 0.9817124009132385, 0.9994387030601501, 0.9800031781196594]\n",
      "[8.10855484008789, 0.4633943438529968, 0.5973940491676331, 0.4580592215061188]\n",
      "[5.654313087463379, 0.43427619338035583, 0.7056654095649719, 0.4296628534793854]\n",
      "\n",
      "Validation loss: 3.00 +- 3.27\n",
      "Validation accuracy: 75.31% +- 25.14%\n",
      "Validation AUC: 85.49% +- 16.98%\n",
      "Validation f1_score: 73.30% +- 24.63%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the previously trained Keras model\n",
    "model_file = 'C:\\\\Users\\\\jdani\\\\Documents\\\\TrabajoDeGrado\\\\Arquitecturas\\\\ArquitecturaRecurrente\\\\ModelosCheckpointsOptuna\\\\NA\\\\mejor_modelo_trial'\n",
    "modelo='8'\n",
    "model = keras.models.load_model(model_file+modelo+'.h5',custom_objects={'f1': f1})\n",
    "\n",
    "# Load the data for cross-validation\n",
    "X, y = load_data_test_gru()\n",
    "y= keras.utils.to_categorical(y)\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Initialize the KFold class\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "perdida=[]\n",
    "precision=[]\n",
    "auc=[]\n",
    "f1_score=[]\n",
    "\n",
    "# Iterate over the folds\n",
    "for train_indices, val_indices in kf.split(X):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_val, y_val = X[val_indices], y[val_indices]\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    metricas = model.evaluate(X_val, y_val, verbose=0)\n",
    "    perdida.append(metricas[0])\n",
    "    precision.append(metricas[1]*100)\n",
    "    auc.append(metricas[2]*100)\n",
    "    f1_score.append(metricas[3]*100)\n",
    "    \n",
    "    print(metricas)\n",
    "print()\n",
    "print('Validation loss: {:.2f} +- {:.2f}'.format(np.mean(perdida), np.std(perdida)))\n",
    "print('Validation accuracy: {:.2f}% +- {:.2f}%'.format(np.mean(precision), np.std(precision)))\n",
    "print('Validation AUC: {:.2f}% +- {:.2f}%'.format(np.mean(auc), np.std(auc)))\n",
    "print('Validation f1_score: {:.2f}% +- {:.2f}%'.format(np.mean(f1_score), np.std(f1_score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
